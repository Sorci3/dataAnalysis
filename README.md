# RÃ©sumÃ© du Projet
Ce projet s'inscrit dans le cadre d'une mission pour une sociÃ©tÃ© financiÃ¨re spÃ©cialisÃ©e dans les crÃ©dits Ã  la consommation pour des clients ayant peu ou pas d'historique de prÃªt. L'objectif principal est de dÃ©velopper un outil complet de Credit Scoring capable de prÃ©dire automatiquement la probabilitÃ© de faillite d'un client et de classifier chaque demande en crÃ©dit accordÃ© ou refusÃ©.

## Objectifs MÃ©tiers et Contraintes
L'enjeu central est de construire un modÃ¨le performant tout en rÃ©pondant Ã  deux contraintes mÃ©tier majeures :

- #### Le dÃ©sÃ©quilibre des classes : 
Le jeu de donnÃ©es prÃ©sente une forte disproportion entre les bons et les mauvais payeurs, nÃ©cessitant des techniques de rÃ©Ã©quilibrage adaptÃ©es
- #### L'asymÃ©trie des coÃ»ts (CoÃ»t FN vs FP) :
Un Faux NÃ©gatif (FN) (accorder un crÃ©dit Ã  un client qui ne payera pas) est considÃ©rÃ© comme beaucoup plus coÃ»teux qu'un Faux Positif (FP) (refuser un crÃ©dit Ã  un bon client).L'hypothÃ¨se mÃ©tier retenue est qu'un FN coÃ»te environ 10 fois plus cher qu'un FP ($FN \approx 10 \times FP$)

### Objectif: Optimisation du Seuil de DÃ©cision
En raison de cette asymÃ©trie, l'utilisation du seuil de classification standard (0.5) n'est pas pertinente. Une fonction de coÃ»t mÃ©tier personnalisÃ©e a Ã©tÃ© dÃ©finie pour pÃ©naliser fortement les Faux NÃ©gatifs. L'objectif final est d'optimiser le seuil de dÃ©cision pour minimiser ce coÃ»t total, garantissant ainsi une rentabilitÃ© optimale pour l'institution financiÃ¨re tout en maÃ®trisant le risque.


# Lancement du projet
**Assurez-vous d'Ãªtre Ã  la racine du projet.**

Installation des dÃ©pendances :
```Bash
pip instaLL -r requirements.txt
```

Construction de l'image docker : 
```Bash
docker build -t credit-scoring-model .
```
Lancement du conteneur :
```Bash
docker run -p 1234:1234 credit-scoring-model
```

# Seuil mÃ©tier
Le seuil mÃ©tier optimal est le point d'Ã©quilibre prÃ©cis qui permet Ã  la banque de maximiser sa rentabilitÃ©. Ce seuil est la barriÃ¨re que l'on fixe pour prendre la dÃ©cision (probabilitÃ© > Seuil $\rightarrow$ Refus | probabilitÃ© < Seuil $\rightarrow$ Accord).Dans notre notebook 02_model_training.ipynb, nous avons dÃ©terminÃ© que le modÃ¨le offrant le meilleur compromis est LightGBM (une fois optimisÃ©). GrÃ¢ce Ã  lui, nous obtenons un seuil optimal de 0,51 pour un coÃ»t mÃ©tier de 29 761. Par consÃ©quent, si un client a une probabilitÃ© de dÃ©faut de 47 %, il doit Ãªtre refusÃ©, alors que s'il a une probabilitÃ© de 45 %, il doit Ãªtre acceptÃ©.

# Structure du projet
PROJET-CREDIT-SCORING/
â”‚
â”œâ”€â”€ ğŸ“‚ src/                          # LE MOTEUR (Code source modulaire)
â”‚   â”œâ”€â”€ data_prep.py                # Pipeline de transformation des donnÃ©es brutes
â”‚   â”œâ”€â”€ model_utils.py              # Logique d'entraÃ®nement, Cross-Val et Optuna
â”‚   â”œâ”€â”€ metrics.py                  # DÃ©finition mathÃ©matique du coÃ»t mÃ©tier
â”‚   â””â”€â”€ explainability.py           # Moteur d'interprÃ©tabilitÃ© (SHAP)
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/                    # LES EXPÃ‰RIENCES (Notebooks)
â”‚   â”œâ”€â”€ 01_data_preparation.ipynb   # ExÃ©cution du pipeline de nettoyage
â”‚   â”œâ”€â”€ 02_model_training.ipynb     # Orchestration des entraÃ®nements et MLflow
â”‚   â”œâ”€â”€ 03_explainability.ipynb     # Analyse des dÃ©cisions du modÃ¨le
â”‚   â””â”€â”€ 04_mlflow_serving_test.ipynb # Simulation client / test API
â”‚
â”œâ”€â”€ ğŸ“‚ model/                        # Artefact final
â”œâ”€â”€ ğŸ“‚ mlruns/                       # Base de donnÃ©es de tracking (Logs)
â”œâ”€â”€ Dockerfile                      # Fichier de mise en place Docker
â””â”€â”€ requirements.txt                # Liste des dÃ©pendances (pip)



